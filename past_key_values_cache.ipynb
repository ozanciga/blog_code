{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def get_fixed_past_key_values(model, tokenizer, fixed_text, batch_size):\n",
    "    fixed_tokens = tokenizer(fixed_text, return_tensors=\"pt\", ).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        fixed_outputs = model(fixed_tokens['input_ids'], )\n",
    "        past_key_values_batch = tuple(tuple(tensor.repeat(batch_size, 1, 1, 1) for tensor in layer) for layer in fixed_outputs.past_key_values)\n",
    "    return past_key_values_batch\n",
    "\n",
    "\n",
    "def make_variable_text(prompt):\n",
    "    # phi-3 expects this template\n",
    "    return '''\n",
    "    {{prompt}}\n",
    "    <|end|>\n",
    "    <|assistant|>'''.replace('{{prompt}}', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = tokenizer_id = \"microsoft/Phi-3-medium-4k-instruct\"\n",
    "model_kwargs = {'device_map': \"cuda\", 'torch_dtype': \"auto\", 'trust_remote_code': True, 'attn_implementation': \"flash_attention_2\"}\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id, trust_remote_code=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_text = '''\n",
    "<|endoftext|><|user|>\n",
    "Write me a poem about below prompt.\n",
    "\n",
    "Prompt: '''\n",
    "\n",
    "variable_texts = ['yesterday', 'here today', 'another day', 'a day in life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "past_key_values_batch = get_fixed_past_key_values(model, tokenizer, fixed_text, batch_size)\n",
    "batches = [[fixed_text+make_variable_text(prompt) for prompt in variable_texts[i:i+batch_size]] for i in range(0, len(variable_texts), batch_size)]  # this is for demonstration. use datasets library in production. also doesnt account for len(dataset)/batch size != integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:22<00:00, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Write me a poem about below prompt.\n",
      "\n",
      "Prompt: \n",
      "    yesterday\n",
      "     In yesterdays soft embrace I stand,\n",
      "Reflections laced within my hand,\n",
      "A day that passed to memory's band,\n",
      "A fleeting whisper in time's vast sand.\n",
      "\n",
      "The glow of morning's tender kiss,\n",
      "Upon the cheeks where dreams can't miss,\n",
      "The dance of flitting moments' bliss,\n",
      "Yet now enshrouded in the amiss.\n",
      "\n",
      "Yesterday, a painted sky,\n",
      "With a hue of joy that never lies,\n",
      "The laughter of the gentle skies,\n",
      "An echo of what never dies.\n",
      "\n",
      "A symphony of life replayed,\n",
      "A chapter whose edges now decayed,\n",
      "In yesterday's garden, love once sown,\n",
      "Harvest memories, softly grown.\n",
      "\n",
      "Footsteps retraced on wornened paths,\n",
      "Through fields of whispering, autumnal waths,\n",
      "Where the rustling leaves spoke in math,\n",
      "Of time and space, and their infinite swath.\n",
      "\n",
      "A tender gaze on friends held dear,\n",
      "The warmth of their love so sincere,\n",
      "The sharing of a moment's cheer,\n",
      "\n",
      " Write me a poem about below prompt.\n",
      "\n",
      "Prompt: \n",
      "    here today\n",
      "     Here Today\n",
      "\n",
      "Amid the boundless dance of cosmic rays,\n",
      "A moment born, a fleeting breath, a blaze,\n",
      "Here I stand, with open arms to seize\n",
      "The whispered wonders of these bending trees.\n",
      "\n",
      "Here today, beneath a sky of sapphire hue,\n",
      "Where daylight weaves its golden threads anew,\n",
      "I'm cradled by the soft caress of dawn,\n",
      "And carried upon the breath of break of morn.\n",
      "\n",
      "Here, where time seems paused, and heartbeats slow,\n",
      "I find the now, the present where I flow,\n",
      "A single droplet melding with the sea\n",
      "Of life, reflecting all eternity.\n",
      "\n",
      "Here is the ticking clock, the sound so clear,\n",
      "A reminder of the precious moments dear,\n",
      "Each tick a step on life's unwinding thread,\n",
      "Each tock, a call to live with open head.\n",
      "\n",
      "Here today, with every gentle breeze,\n",
      "I breathe the life I know, I share the ease,\n",
      "Of souls allied within this ephemeral day,\n",
      "A bond unbroken in\n",
      "\n",
      " Write me a poem about below prompt.\n",
      "\n",
      "Prompt: \n",
      "    another day\n",
      "     Beneath the vast cerulean dome,\n",
      "Begins another day of home.\n",
      "Night’s sweet reprieve is cast aside,\n",
      "The world awakens, stretched out wide.\n",
      "\n",
      "A stirring, gentle, rhythmic tide,\n",
      "As life emerges side by side.\n",
      "Rays of the sun, a warm caress,\n",
      "Upon the earth, they paint with zest.\n",
      "\n",
      "Another day, another breath,\n",
      "A dance with life, defiance of death.\n",
      "New joys and trials yet untold,\n",
      "A story yet to be enfolded and unfolded.\n",
      "\n",
      "A fluttering leaf, a bird's first song,\n",
      "The sun that climbs the sky all day long.\n",
      "Each moment precious, yet swift it flies,\n",
      "Another day, another sunrise.\n",
      "\n",
      "Amidst the chaos, love may bloom,\n",
      "Amidst the heartache, resilience becomes.\n",
      "Every dawn, a chance to heal,\n",
      "Beneath another day's renewing wheel.\n",
      "\n",
      "So we embrace this latest start,\n",
      "Thankful for the beating of our heart.\n",
      "For each\n",
      "\n",
      " Write me a poem about below prompt.\n",
      "\n",
      "Prompt: \n",
      "    a day in life\n",
      "     In a life so simple and so fast,\n",
      "A day dawns, a day has passed.\n",
      "From breaking light to the velvet night,\n",
      "In the day's swift journey, both high and slight.\n",
      "\n",
      "Awakened by rooster's clarion call,\n",
      "Awash with daybreak's amber pall.\n",
      "Open eyes, a world unknown,\n",
      "A day begun, in soft twilight sown.\n",
      "\n",
      "Greet the morning, with fresh dew on leaf,\n",
      "A symphony serenades belief.\n",
      "A warm cup of coffee, a bite for the sweet,\n",
      "The taste of the moment, unbeatable, complete.\n",
      "\n",
      "A sprint of the heart, a toil in hand,\n",
      "A day's duty, life's commanding band.\n",
      "In quiet moments, a thoughtful sigh,\n",
      "A pause for peace in a hurried lie.\n",
      "\n",
      "Whispers of the wind, secrets it bore,\n",
      "A tale of times on that distant shore.\n",
      "Fields of gold waving tenderly,\n",
      "A heart echoing life's melody.\n",
      "\n",
      "A day’s task completed, under the sun's keen gaze,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "do_sample, use_cache = True, True\n",
    "max_new_tokens = 256\n",
    "\n",
    "for _, batch in enumerate(tqdm(batches, )):\n",
    "    new_prompt_tokens = tokenizer(batch, return_tensors='pt', padding=True, ).to(\"cuda\")\n",
    "    output_tokens = model.generate(\n",
    "        new_prompt_tokens['input_ids'], \n",
    "        max_new_tokens=max_new_tokens,\n",
    "        past_key_values=past_key_values_batch if use_cache else None, \n",
    "        use_cache=use_cache,\n",
    "        do_sample=do_sample,\n",
    "    )\n",
    "    outputs.extend(tokenizer.batch_decode(output_tokens, skip_special_tokens=True))\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
